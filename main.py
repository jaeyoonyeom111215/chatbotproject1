import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_id = "meta-llama/Meta-Llama-3-8B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)

# ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
def display_conversation_history(history):
    for item in history:
        if item['role'] == 'user':
            st.write(f"ì‚¬ìš©ì: {item['content']}")
        else:
            st.write(f"ì±—ë´‡: {item['content']}")

# ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    st.title("Llama 3ğŸ¦™")

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    conversation_history = []

    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    user_input = st.text_input("ì‚¬ìš©ì ì…ë ¥:")

    # ì‚¬ìš©ìê°€ ì…ë ¥ì„ ì œê³µí•œ ê²½ìš°
    if user_input:
        # ì‚¬ìš©ì ì…ë ¥ì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        conversation_history.append({"role": "user", "content": user_input})

        # ì±—ë´‡ ì‘ë‹µ ìƒì„±
        input_ids = tokenizer.apply_chat_template(
            conversation_history,
            add_generation_prompt=True,
            return_tensors="pt"
        ).to(model.device)

        terminators = [
            tokenizer.eos_token_id,
            tokenizer.convert_tokens_to_ids("")
        ]

        outputs = model.generate(
            input_ids,
            max_new_tokens=256,
            eos_token_id=terminators,
            do_sample=True,
            temperature=0.6,
            top_p=0.9,
        )
        bot_response = outputs[0][input_ids.shape[-1]:]
        bot_response_text = tokenizer.decode(bot_response, skip_special_tokens=True)

        # ì±—ë´‡ ì‘ë‹µì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        conversation_history.append({"role": "system", "content": bot_response_text})

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
        display_conversation_history(conversation_history)

if __name__ == "__main__":
    main()
